### 逻辑回归

基本的逻辑回归是一个二元分类器，通过将输入数据通过向量w映射到logistic函数的输入，一个事情发生的概率为p，那么发生的几率为log(p/(1-p))=wx。多分类使用多项逻辑回归（softmax）。

对于分类问题，逻辑回归应用于线性可分的数据集，因为逻辑回归实际上还是对数据给出一个超平面来将数据集分为两部分。对二维数据来说，如果数据可以被一条线分为两个部分，那么就可以应用logistic回归来进行分类；如果数据分布呈现环装分布或者螺旋分布，那么就难以找到这样一条线正确分类；

### 决策树

决策树是不断的使用垂直于坐标轴的直线来对空间进行划分，通常可以被用于分类问题ID3，C4.5，以及回归问题CART。简单直观，解释性强。

对于分类问题，如果类别的边界可以通过垂直坐标轴直线所组成的边界不断的分割，最终得到某一个类别的区域，那么该数据集用决策树效果就比较好。**如果边界是非线性的，并且能通过不断将特征空间切分为矩形来模拟，那么决策树是比逻辑回归更好的选择**。

问题：

信息增益最大的为什么具有更强的分类能力：信息增益反应某类特征降低系统不确定性的程度；

Gini指数：优先选择Gini指数小的特征；

#### 