### 特征工程
1. 常用的两种数据类型： a. 结构化数据，包含数值型，类别型；b. 非结构化数据，图像视频音频等无法用简单数值表示；
2. 为什么要对数值型特征归一化：消除量纲影响，使不同指标具有可比性；
3. 特征归一化的两种方法：a: 线性函数归一化，0~1， b. 零均值归一化：$\mu=0, \sigma=1$ ；
4. 类别型特征（血型，性别等）转化为数字特征才能对SVM等进行应用：a. 序号编码，b. 独热编码, c. 二进制编码；
5. 什么是高维组合特征？一阶离散特征两两组合。处理方法：降维；
6. 如何找到有效的组合特征：决策树
7. 常用文本表示模型及特性： a. 词袋模型和N-gram：$TF-IDF(t,d)=TF(t,d) IDF(t) $ ; （忽略顺序）b. 主题模型; c. 词嵌入模型与深度学习模型
8. Word2Vec词嵌入模型，两种网络结构：CBOW(continues bag of words)--从上下文预测当前词；skip-gram--从当前词预测其他词概率；
9. 图像数据不足的处理办法：a. 采用旋转，平移缩放，裁剪填充；b. 添加噪声扰动；c. 颜色变换；d. 改变对比度，锐度等 e. 生成对抗网络扩充样本；f. 上采样如SMOTE(Synthetic Minority Over-sampling Technique) e. 迁移学习，从已有模型fine-tune; 

### 模型评估
N为负样本个数，P为正样本个数
1. 准确率：Accuracy=正确分类样本数  / 总样本数；当不同类别样本比例分布非常不均匀时，占大比例的样本往往成为影响准确率的因素；
2. 精确率与召回率：精确率precision=正确分类正样本数 / 判定为正样本个数，召回率recall=正确分类样本 / 真正正样本的个数；
   P-R曲线会随样本数变化而剧烈变化；F1=2/(1/R+1/P)可以反应模型的性能；
3. 均方根误差RMSE: 优点：能够很好的反应回归模型的预测值与真实值的偏离程度，缺点：会受离群点的严重影响；
4. ROC曲线：Receiver Operating Characteristic Curve. 横轴：假阳性率FPR=FP/N，纵轴：真阳性率TPR=TP/P。优点：不随数据规模剧烈变化；
5. ROC绘制：a. 从高到低动态的调整截断点（阈值）逐阈值，每隔一段阈值绘制一个点 b. 逐样本，每个样本绘制一个点； 
6. AUC：积分计算ROC下面积，0.5~1之间，越大越好
7. 余弦距离比欧氏距离优点：数值范围固定：对高维特征有很好的度量性，不受围度影响；
8. 余弦距离为什么不是严格定义距离，满足正定性，对称性，不满足三角不等式；证明：dist{A, B}=1/2 |A-B|^2，欧氏距离是一个严格的距离，所以余弦距离不是；
9. 超参数调优方法：网格搜索，随机搜索，贝叶斯优化
10. 自助采样法有多少样本未被选择：36.8%，lim(1-1/n)=1/e
11. 降低过拟合和欠拟合方法，过拟合：a. 正则，b. 集成学习 c. 更多数据 d. 降低模型复杂度
欠拟合：a. 减小正则，b. 增加模型复杂度，c. 增加特征；